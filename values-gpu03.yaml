nameOverride: ""

ollama:
  # -- Automatically install Ollama Helm chart from https://otwld.github.io/ollama-helm/. Use [Helm Values](https://github.com/otwld/ollama-helm/#helm-values) to configure
  enabled: true
  # -- If enabling embedded Ollama, update fullnameOverride to your desired Ollama name value, or else it will use the default ollama.name value from the Ollama chart
  fullnameOverride: "open-webui-ollama"
  # -- Example Ollama configuration with nvidia GPU enabled, automatically downloading a model, and deploying a PVC for model persistence
  ollama:
    gpu:
      enabled: true
      type: 'nvidia'
      number: 3
    models:
      - llama3.1:8b
  # runtimeClassName: nvidia
  persistentVolume:
    enabled: true
  #   volumeName: "example-pre-existing-pv-created-by-smb-csi"
    size: 200Gi
